---
title: "Memory-aware Framework for Fast and Scalable Second-order Random Walk over Billion-edge Natural Graphs"
collection: publications
permalink: /publication/2021-randomwalk
excerpt: 'Efficient second-order random walk framework (journal extension).'
date: 2021-05-07
venue: 'The VLDB Journal'
paperurl: 'https://link.springer.com/article/10.1007/s00778-021-00669-2'
citation: 'Shao, Y., Huang, S., Li, Y., Miao, X., Cui, B., & Chen, L. (2021). Memory-aware framework for fast and scalable second-order random walk over billion-edge natural graphs. The VLDB Journal, 30(5), 769-797.'
---
Second-order random walk is an important technique for graph analysis. Many applications including graph embedding, proximity measure and community detection use it to capture higher-order patterns in the graph, thus improving the model accuracy. However, the memory explosion problem of this technique hinders it from analyzing large graphs. When processing a billion-edge graph like Twitter, existing solutions (e.g., alias method) of the second-order random walk may take up 1796TB memory. Such high memory consumption comes from the memory-unaware strategies for the node sampling during the random walk. In this paper, to clearly compare the efficiency of various node sampling methods, we first design a cost model and propose two new node sampling methods: one follows the acceptance-rejection paradigm to achieve a better balance between memory and time cost, and the other is optimized for fast sampling the skewed probability distributions existed in natural graphs. Second, to achieve the high efficiency of the second-order random walk within arbitrary memory budgets, we propose a novel memory-aware framework on the basis of the cost model. The framework applies a cost-based optimizer to assign desirable node sampling method for each node or edge in the graph within a memory budget meanwhile minimizing the time cost of the random walk. Finally, the framework provides general programming interfaces for users to define new second-order random walk models easily. The empirical studies demonstrate that our memory-aware framework is robust with respect to memory and is able to achieve considerable efficiency by reducing 90% of the memory cost.